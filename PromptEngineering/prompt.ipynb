{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll use LangChain.\n",
    "- Langchain is a framework for developing applications powered by large language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"API_KEY\"\n",
    "    print('API_KEY set properly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Shot Prompting\n",
    "- Asking the model to perform a task without giving any example.\n",
    "- When you want quick result and the task is simple or well-known\n",
    "- Example:\n",
    "    - Translate the following English sentence to French: \"How are you?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"How are you?\" in French is \"Comment ça va ?\" or simply \"Ça va ?\" for a more informal approach. If you want to be more formal, you can say \"Comment allez-vous ?\"\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"Translate the sentences to French:{sentence}\")\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "print(chain.run(\"How are you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Shot Prompting\n",
    "- Providing one example of the task along with the instruction.\n",
    "- Useful when the model needs a little context or format guidance.\n",
    "- Example\n",
    "    - prompt = \"\"\"Translate the following sentence to French.\n",
    "        Example: \"I love apples.\" → \"J'aime les pommes.\"\n",
    "        Now translate: \"Good morning.\"\"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"size\": \"large\",\n",
      "    \"type\": \"normal\",\n",
      "    \"ingredients\": [[\"cheese\", \"mozzarella\"], [\"tomato sauce\", \"ham\", \"pineapple\"]]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Parse a customer's pizza order into a valid JSON:\n",
    "Example: \n",
    "I want a small pizza with cheese, tomato sauce, and pepperoni.\n",
    "JSON Response:\n",
    "{{\n",
    "    \"size\" : \"small\",\n",
    "    \"type\" : \"normal\",\n",
    "    \"ingredients\" : [[\"cheese\", \"tomato sauce\", \"pepperoni\"]]\n",
    "}}\n",
    "Now Parse this customer order: {sentence}\n",
    "Respond only with the JSON object.\n",
    "JSON Response:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables = [\"sentence\"],template=template)\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "response = chain.run(\"I would like a large pizza, with the first half cheese and mozzarella. And the other tomato sauce, ham and pineapple.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Prompting\n",
    "- Providing multiple examples to show model a pattern.\n",
    "- Works well when the task requires context or formatting that zero-shot fails to capture.\n",
    "- examples = {\n",
    "    \"I am a student\" : \"আমি একজন ছাত্র।\"\n",
    "    \"The sky is blue\" : \"আকাশ নীল\"\n",
    "    \"They are eating.\": \"তারা খাচ্ছে।\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She is happy. -> সে খুশি।\n",
      "**********\n",
      "He is a brilliant student. -> তিনি একজন উজ্জ্বল ছাত্র।\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    (\"I am a student.\", \"আমি একজন ছাত্র।\"),\n",
    "    (\"The sky is blue\", \"আকাশ নীল\"),\n",
    "    (\"They are eating.\", \"তারা খাচ্ছে।\")\n",
    "]\n",
    "example_str = \"\\n\".join([f\"{eng}->{ben}\" for eng, ben in examples])\n",
    "template = f\"\"\"Translate these sentences:\n",
    "{example_str}\n",
    "translate: {{sentence}}\"\"\"\n",
    "Prompt = PromptTemplate.from_template(template)\n",
    "chain = LLMChain(llm=llm,prompt=Prompt)\n",
    "response = chain.run(\"She is happy.\")\n",
    "response1 = chain.run(\"He is a briliant student\")\n",
    "print(response)\n",
    "print(\"*\"*10)\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain-of-Thought Prompting\n",
    "- Asking the model to explain its reasoning step-by-step before giving the final answer.\n",
    "- Effective in reasoning-based tasks like math, logic puzzles, and complex decision making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step-by-step:\n",
      "\n",
      "1. **Initial Count**: You start with 5 pens.\n",
      "2. **Taking Away**: You take away 2 pens from the initial 5.\n",
      "3. **Your Count**: Since you took away 2 pens, you now have those 2 pens in your possession.\n",
      "\n",
      "So, the answer is that you have 2 pens.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Question: {question}\\nThink step-by-step.\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "response = chain.run(\"If there are 5 pens and you take away 2, how many do you have?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Role-Based Prompting\n",
    "- Asking the model to act in a specific role or persona\n",
    "- Ideal for simulations, interviews, support bots and educational uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision trees are a type of model used for making decisions based on data. They work by splitting data into branches based on certain criteria, leading to a final decision or prediction at the leaves. Think of it like a flowchart that helps you choose the best option by asking a series of yes/no questions.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are a senior Data Scientist. Explain decision trees in simple terms to a beginner in 3 lines.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instruction Based prompting\n",
    "- Using natural language instructions to guide the model's behaviour.\n",
    "- Supported heavily in models like GPT-3.5-turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Artificial Intelligence is significantly changing the healthcare industry by enhancing diagnostics, treatment plans, and patient care.\n",
      "- AI technologies are improving efficiency, reducing costs, and enabling personalized medicine in healthcare settings.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the following paragraph in 2 bullet points:\\n\\n{paragraph}\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"Artificial Intelligence is transforming the healthcare industry...\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are different other prompting techniques.\n",
    "- ReAct promting (Reasoning + Actions)\n",
    "- Multimodal Prompting (Langchain with GPT-4-vision)\n",
    "- Prompt chaning\n",
    "- RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
